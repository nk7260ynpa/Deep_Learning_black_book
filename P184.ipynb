{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Train for 500\n",
      "Total iters: 500\n",
      "data_length:  3198882\n",
      "char_list:  98 ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'à', 'á', 'â', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ú', 'ý', '—', '…', '\\ufeff']\n",
      "char_dict:  {'ê': 86, 'R': 43, 'u': 72, 'o': 66, 'ï': 90, 'L': 37, ',': 8, '!': 2, 'á': 80, 'd': 55, 'G': 32, 'V': 47, 'P': 41, 'À': 78, '(': 5, 'í': 88, '/': 11, 'l': 63, '…': 96, 'x': 75, 'n': 65, 'k': 62, '-': 9, 'i': 60, 'é': 85, 'ô': 92, 'a': 52, ':': 22, 'ç': 83, 'Q': 42, '6': 18, ';': 23, 'ä': 82, '—': 95, 'e': 56, 't': 71, '=': 24, 'â': 81, 'c': 54, 'w': 74, 'è': 84, '.': 10, 's': 70, ' ': 1, 'B': 27, 'N': 39, 'à': 79, '8': 20, 'U': 46, '1': 13, 'ú': 93, 'H': 33, 'X': 49, '*': 7, 'C': 28, 'f': 57, 'D': 29, 'I': 34, 'h': 59, 'b': 53, '9': 21, 'ó': 91, '4': 16, 'y': 76, 'ë': 87, 'r': 69, 'Y': 50, '\\n': 0, 'K': 36, '2': 14, 'A': 26, 'W': 48, 'E': 30, 'O': 40, 'v': 73, '7': 19, 'z': 77, 'g': 58, 'Z': 51, 'j': 61, 'S': 44, 'q': 68, 'î': 89, 'p': 67, '\\ufeff': 97, ')': 6, 'M': 38, 'm': 64, 'T': 45, '3': 15, 'F': 31, '5': 17, 'J': 35, 'ý': 94, '0': 12, \"'\": 4, '?': 25, '\"': 3}\n",
      "labels:  ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'à', 'á', 'â', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ú', 'ý', '—', '…', '\\ufeff']\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "i:  50\n",
      "loss: 3.0783753395080566 (7.628497838973999 sec.)\n",
      "i:  100\n",
      "loss: 3.097379446029663 (7.060202121734619 sec.)\n",
      "Reset initial state\n",
      "i:  150\n",
      "loss: 2.889927864074707 (6.802182674407959 sec.)\n",
      "i:  200\n",
      "loss: 2.6146087646484375 (6.877249002456665 sec.)\n",
      "Reset initial state\n",
      "i:  250\n",
      "loss: 2.409074068069458 (6.832391023635864 sec.)\n",
      "i:  300\n",
      "loss: 2.2510623931884766 (6.996102333068848 sec.)\n",
      "Reset initial state\n",
      "i:  350\n",
      "loss: 2.1878702640533447 (7.023778438568115 sec.)\n",
      "i:  400\n",
      "loss: 2.0949671268463135 (7.066756248474121 sec.)\n",
      "Reset initial state\n",
      "i:  450\n",
      "loss: 2.0425591468811035 (7.0346760749816895 sec.)\n",
      "\n",
      " sampling after 500 iterations\n",
      "INFO:tensorflow:Restoring parameters from ./model.tf\n",
      "\n",
      "Sample 1:\n",
      "prime_string:  \n",
      "\n",
      "This feeling was \n",
      "start sampling\n",
      "sample: \n",
      "\n",
      "\n",
      "This feeling was Prince pin cromers martince anf froigh a of thame tu in se soom. Thee for the france sorcartare sare—in flaste... A rathiy.. \"Nis Dase the alo man hand to Fmile—thouteriped wey woom the doite and nith wo Klyinitev the amqooving con fou, Prinon, to hiind, be now, und memebs. And Notíll the find of theurse oferssed as and a ges prained han't ho ame ow qugncand and chanen bit and courding foring thit indying the ragkriald whome to dofn did seild ho to oo the ofler the who coblet ha, of a celild the\n",
      "\n",
      "Sample 2:\n",
      "prime_string:  She was born in the year \n",
      "start sampling\n",
      "sample: \n",
      "She was born in the year dincas has spumringing in woth not to hiur Berran. The hed watlitctry beselrent, led pinss whacine poor—owh firishun with we thl sho comike and he askerd waid.\n",
      "\n",
      "\"A hoved futing and coune and thich Gow's Dyikting fipúon thes? lesy visitire of elettiyity emisurtgrigk—it thay hid to shiis offor to and the pcilllougung, whiccing lroingled tome\" a danting fourd an yhe deigh, sullerow and ham in tould that and whiring skontssyppant of ceveasty as are luthougining; and the grostsoof. Hereided he Rowírs\n",
      "\n",
      "Sample 3:\n",
      "prime_string:  The meaning of this all is \n",
      "start sampling\n",
      "sample: \n",
      "The meaning of this all is wils of promimed mid gan of I corep, and sot bingruete of it agait of  ben glowees taenyen,. \"I ho the shige, de of the kore seziers net conbe as is exare vigclates slecons of haw Rustancert shit the cald nof covering to dealds! I dinge. Is theding a sen the tae'r no cou hilr of the fropssed is a pacíin reptom theil peimáz3n and ay enanceedsy and smathoiir the recedad door frones araed to swore af the paor nourgobbect ow peyy kilpesotd whemens Rostov the gigmks plomrheathed popirg the had purp a\n",
      "\n",
      "Sample 4:\n",
      "prime_string:  In the midst of a conversation on political matters Anna Pávlovna burst out:,\n",
      "start sampling\n",
      "sample: \n",
      "In the midst of a conversation on political matters Anna Pávlovna burst out:, ad cot\" Paerint bound, and ant weing—flem, lotzitss! \"A gar?\" sef enoken in the selleach, hom spoy.\"\n",
      "\n",
      "Molearss he wicurd mancents-fuides yoo ald shiluss, he sach, oud and fand an she andder fressed spipilsed it con moreigg yourde, butided by vishied sintoon peaed will you geal, and this Ipone faving tf cazloce of one and eve\".\". Alanow sying.\" Bagill in hin amy is it itnledde.\n",
      "\n",
      "\"The nough buinangaes I cal a paving, of thu piciund mond te nos bn the seows on kon pegich, bud with a tho rowsrer,. \n",
      "\n",
      "Sample 5:\n",
      "prime_string:  \n",
      "\n",
      "CHAPTER X\n",
      "\n",
      "\n",
      "start sampling\n",
      "sample: \n",
      "\n",
      "\n",
      "CHAPTER X\n",
      "\n",
      "That he che's to diw showe on dood yow dat the meverenlestant farter, at?á\n",
      "\"\"8he abantres of to prot?\"\n",
      "\n",
      "The com, of thit by incerring\" Farisiles, Delores, tit he on he Netánlo co a mavore thesarcide!\n",
      "\n",
      "FWint a. I St tritimy weld gabp ond perered and fich.\n",
      "\n",
      "\"Ald Ruskdov by peimer, Vistle hid gerp cmiminat wite of the spild bicick had't as and the seessone br ce figery and cavufting Prasche on the heryy atelevliting tiy apfoo! Teer was Gornch guteine of the lassedselobf, but of haved yoo prrerfered\n",
      "\n",
      "Sample 5:\n",
      "prime_string:  \"If only you knew,\"\n",
      "start sampling\n",
      "sample: \n",
      "\"If only you knew,\" waln tho lake the poin piseens buce thine hay wish at teet. Rr cund what and ally it colenor! The soneed. Ang way in shalbed?\" serf pvewing in and he sal at intf doorrly dother the frersiara an wis aseoren be and kon freararlost him for warce wat in the adias fording of inflace and wirf abmithem, leice ind frapped exleved deapand to plinged forerss of they mook of withing to conger, bobd ly bears on conss and saysen it \" simess on intithie and spaese. The ofcatwn-be the prenge, ruvbed rappe!s t\n",
      "\n",
      "\n",
      "\n",
      "Train for 500\n",
      "Total iters: 1000\n",
      "data_length:  3198882\n",
      "char_list:  98 ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'à', 'á', 'â', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ú', 'ý', '—', '…', '\\ufeff']\n",
      "char_dict:  {'ê': 86, 'R': 43, 'u': 72, 'o': 66, 'ï': 90, 'L': 37, ',': 8, '!': 2, 'á': 80, 'd': 55, 'G': 32, 'V': 47, 'P': 41, 'À': 78, '(': 5, 'í': 88, '/': 11, 'l': 63, '…': 96, 'x': 75, 'n': 65, 'k': 62, '-': 9, 'i': 60, 'é': 85, 'ô': 92, 'a': 52, ':': 22, 'ç': 83, 'Q': 42, '6': 18, ';': 23, 'ä': 82, '—': 95, 'e': 56, 't': 71, '=': 24, 'â': 81, 'c': 54, 'w': 74, 'è': 84, '.': 10, 's': 70, ' ': 1, 'B': 27, 'N': 39, 'à': 79, '8': 20, 'U': 46, '1': 13, 'ú': 93, 'H': 33, 'X': 49, '*': 7, 'C': 28, 'f': 57, 'D': 29, 'I': 34, 'h': 59, 'b': 53, '9': 21, 'ó': 91, '4': 16, 'y': 76, 'ë': 87, 'r': 69, 'Y': 50, '\\n': 0, 'K': 36, '2': 14, 'A': 26, 'W': 48, 'E': 30, 'O': 40, 'v': 73, '7': 19, 'z': 77, 'g': 58, 'Z': 51, 'j': 61, 'S': 44, 'q': 68, 'î': 89, 'p': 67, '\\ufeff': 97, ')': 6, 'M': 38, 'm': 64, 'T': 45, '3': 15, 'F': 31, '5': 17, 'J': 35, 'ý': 94, '0': 12, \"'\": 4, '?': 25, '\"': 3}\n",
      "labels:  ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'à', 'á', 'â', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ú', 'ý', '—', '…', '\\ufeff']\n",
      "Restoring model\n",
      "INFO:tensorflow:Restoring parameters from ./model.tf\n",
      "i:  50\n",
      "loss: 1.8779455423355103 (7.632145643234253 sec.)\n",
      "i:  100\n",
      "loss: 1.8092809915542603 (7.193695306777954 sec.)\n",
      "Reset initial state\n",
      "i:  150\n",
      "loss: 1.7854772806167603 (7.095461130142212 sec.)\n",
      "i:  200\n",
      "loss: 1.7809404134750366 (7.120842933654785 sec.)\n",
      "Reset initial state\n",
      "i:  250\n",
      "loss: 1.7224116325378418 (7.139124870300293 sec.)\n",
      "i:  300\n",
      "loss: 1.6959364414215088 (7.154404401779175 sec.)\n",
      "Reset initial state\n",
      "i:  350\n",
      "loss: 1.6983275413513184 (7.151209831237793 sec.)\n",
      "i:  400\n",
      "loss: 1.6285121440887451 (7.079231023788452 sec.)\n",
      "Reset initial state\n",
      "i:  450\n",
      "loss: 1.5554851293563843 (7.518705606460571 sec.)\n",
      "\n",
      " sampling after 500 iterations\n",
      "INFO:tensorflow:Restoring parameters from ./model.tf\n",
      "\n",
      "Sample 1:\n",
      "prime_string:  \n",
      "\n",
      "This feeling was \n",
      "start sampling\n",
      "sample: \n",
      "\n",
      "\n",
      "This feeling was now they he bright to detimoabs and the timping housh spreised that he peoply, wepe a curnow would who had a time beant Moscipled ablay Bell, del is it the dept plech was which the hand pitud and trowing it the brood by brouben thr those arou take to gnarom seaving his s un havs bet op his been from condining stated, a ampreacte. It was looking a RussI... \"I not may undored for.. \"I from Dozy,... Untry Rostóv... ane \"I have actures, misimen,\" he diver lis as us fron he was thought. \"Grom was tha\n",
      "\n",
      "Sample 2:\n",
      "prime_string:  She was born in the year \n",
      "start sampling\n",
      "sample: \n",
      "She was born in the year even to chalgne.\n",
      "\n",
      "\"Nenicous. Bedifate were ull it, be on the mordunt to carrs out Wopld, Cher. We say in this stop the held no raby, the so, see. I'k, who dally trikgn?\" and dimen a. I dading,\n",
      "\n",
      "\n",
      "\"I don't it!\" I sam with the afuth.\n",
      "\n",
      "\"A 12 those Rostó skink!\" said on!\" he exper and he diling, and demmed.\n",
      "\n",
      "\"Neny, cay a shile, the said to comt my counto the fraso inteparre lescrided. Cat. I ther had \"what?\"\n",
      "\n",
      "\"U do load Ordort laiganck.\"\n",
      "\n",
      "\"I'lly caltken.\n",
      "\n",
      "\"But for he tord of hon in ordens with you.\n",
      "Y\n",
      "\n",
      "Sample 3:\n",
      "prime_string:  The meaning of this all is \n",
      "start sampling\n",
      "sample: \n",
      "The meaning of this all is lone of circlect dulbed the stattluld him. The cannunos hoo pacictar, he hopsed inquise ail wrots accoald-what weak op a but know to the vieth of housepliely of the iser—Ray with the drov by at Anwt. Shy she into the commanders and inne, preard who man drowilly was it have is, but lap tever rellimd and ourly? With e clet having no, Prathar had book had not I man midde.\n",
      "\n",
      "He ad this Naconhov was evintime, without lesso ther wilasal reod his, Gursely and Brea stiy. The long question of agrapabtrent\n",
      "\n",
      "Sample 4:\n",
      "prime_string:  In the midst of a conversation on political matters Anna Pávlovna burst out:,\n",
      "start sampling\n",
      "sample: \n",
      "In the midst of a conversation on political matters Anna Pávlovna burst out:, yaid becad aplenom art, malisal was the pries. A hoursh, a move of Vury shmirg Napolkov Danime's an one surning to speford the face prepberad.\n",
      "\n",
      "\"Who man I'clpbod,\" he dove, cOncems as a belt ap, and Mary Krpaticular him, and talk butte some of Bulubees, liunded with him quaztion active, the guren.\n",
      "\n",
      "\"I 12 Murqrow her prorestly: \"I have a ginkh kis wally travime of ineistly. \"Yof I can wer, all the \"rexagnz, act, and my and Iyen graited a stood.\n",
      "\n",
      "\"Why, look!\" he ear it tat is, I do? \"Lárth's rung\n",
      "\n",
      "Sample 5:\n",
      "prime_string:  \n",
      "\n",
      "CHAPTER X\n",
      "\n",
      "\n",
      "start sampling\n",
      "sample: \n",
      "\n",
      "\n",
      "CHAPTER X\n",
      "\n",
      "A thet ge and those from the bring a che sams in That you freed you fall say no wad the derisitibnur bascing that with a smided more movert the soldie far peftthing not frenting on thew, begait and taking if Mileccers roice convurself, had his eyes. \"Yes ene, and from in the Easteold flink had adrosmed. The frink and some to grince!...\"\n",
      "\n",
      "Frencens provine a general thist at a Frenct. \n",
      "Fvor you, taking since, who had drinces of a fellatate of will was greptions fourge that a romerss—and evinged no\n",
      "\n",
      "Sample 5:\n",
      "prime_string:  \"If only you knew,\"\n",
      "start sampling\n",
      "sample: \n",
      "\"If only you knew,\" said she taken it sond the prenobly—now was hand a did exprecce,, she back!\"\n",
      "\n",
      "\"You the hown from was a chering to me,\" speatov on.\n",
      "\n",
      "\"I thy lad been had there to chat could brid the doince ase on.\n",
      "\n",
      "\"You went us!\" said new prozingly at, a man but I —Not a infy those with this rencluction.\n",
      "\n",
      "\"I am all I'k \"I at the just in who had the, the jond those.\"\n",
      "\n",
      "\"I, yo timile he deagither.\n",
      "\n",
      "\"Beh move com.\"\n",
      "* Dhind our shist his sperogane.\"\n",
      "\n",
      "Aver't cave, they was, with us exceaver? H's enceptions that man wa\n",
      "\n",
      "\n",
      "\n",
      "Train for 1000\n",
      "Total iters: 2000\n",
      "data_length:  3198882\n",
      "char_list:  98 ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'à', 'á', 'â', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ú', 'ý', '—', '…', '\\ufeff']\n",
      "char_dict:  {'ê': 86, 'R': 43, 'u': 72, 'o': 66, 'ï': 90, 'L': 37, ',': 8, '!': 2, 'á': 80, 'd': 55, 'G': 32, 'V': 47, 'P': 41, 'À': 78, '(': 5, 'í': 88, '/': 11, 'l': 63, '…': 96, 'x': 75, 'n': 65, 'k': 62, '-': 9, 'i': 60, 'é': 85, 'ô': 92, 'a': 52, ':': 22, 'ç': 83, 'Q': 42, '6': 18, ';': 23, 'ä': 82, '—': 95, 'e': 56, 't': 71, '=': 24, 'â': 81, 'c': 54, 'w': 74, 'è': 84, '.': 10, 's': 70, ' ': 1, 'B': 27, 'N': 39, 'à': 79, '8': 20, 'U': 46, '1': 13, 'ú': 93, 'H': 33, 'X': 49, '*': 7, 'C': 28, 'f': 57, 'D': 29, 'I': 34, 'h': 59, 'b': 53, '9': 21, 'ó': 91, '4': 16, 'y': 76, 'ë': 87, 'r': 69, 'Y': 50, '\\n': 0, 'K': 36, '2': 14, 'A': 26, 'W': 48, 'E': 30, 'O': 40, 'v': 73, '7': 19, 'z': 77, 'g': 58, 'Z': 51, 'j': 61, 'S': 44, 'q': 68, 'î': 89, 'p': 67, '\\ufeff': 97, ')': 6, 'M': 38, 'm': 64, 'T': 45, '3': 15, 'F': 31, '5': 17, 'J': 35, 'ý': 94, '0': 12, \"'\": 4, '?': 25, '\"': 3}\n",
      "labels:  ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'à', 'á', 'â', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ú', 'ý', '—', '…', '\\ufeff']\n",
      "Restoring model\n",
      "INFO:tensorflow:Restoring parameters from ./model.tf\n",
      "i:  50\n",
      "loss: 1.682519793510437 (7.588531732559204 sec.)\n",
      "i:  100\n",
      "loss: 1.5310152769088745 (7.427866220474243 sec.)\n",
      "Reset initial state\n",
      "i:  150\n",
      "loss: 1.4956060647964478 (7.2963831424713135 sec.)\n",
      "i:  200\n",
      "loss: 1.4460861682891846 (7.389071226119995 sec.)\n",
      "Reset initial state\n",
      "i:  250\n",
      "loss: 1.4622541666030884 (7.27742862701416 sec.)\n",
      "i:  300\n",
      "loss: 1.4190433025360107 (7.130422353744507 sec.)\n",
      "Reset initial state\n",
      "i:  350\n",
      "loss: 1.3917590379714966 (7.342633008956909 sec.)\n",
      "i:  400\n",
      "loss: 1.4389804601669312 (7.244701862335205 sec.)\n",
      "Reset initial state\n",
      "i:  450\n",
      "loss: 1.3922468423843384 (7.192455530166626 sec.)\n",
      "i:  500\n",
      "loss: 1.43300199508667 (7.227404356002808 sec.)\n",
      "Reset initial state\n",
      "i:  550\n",
      "loss: 1.3648358583450317 (7.106108665466309 sec.)\n",
      "i:  600\n",
      "loss: 1.3750308752059937 (7.134047031402588 sec.)\n",
      "Reset initial state\n",
      "i:  650\n",
      "loss: 1.3637733459472656 (7.209409713745117 sec.)\n",
      "i:  700\n",
      "loss: 1.3373196125030518 (7.172760248184204 sec.)\n",
      "Reset initial state\n",
      "i:  750\n",
      "loss: 1.3389712572097778 (7.158612966537476 sec.)\n",
      "i:  800\n",
      "loss: 1.2822859287261963 (7.221952438354492 sec.)\n",
      "Reset initial state\n",
      "i:  850\n",
      "loss: 1.3231011629104614 (7.180232286453247 sec.)\n",
      "i:  900\n",
      "loss: 1.317562222480774 (7.132517337799072 sec.)\n",
      "Reset initial state\n",
      "i:  950\n",
      "loss: 1.3192983865737915 (7.169329881668091 sec.)\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Failed to rename: ./model.tf.data-00000-of-00001.tempstate17407603199646018557 to: ./model.tf.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, logit_bias/_67, logit_weights/_69, rnn/multi_rnn_cell/cell_0/lstm_cell/bias/_71, rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/_73, rnn/multi_rnn_cell/cell_1/lstm_cell/bias/_75, rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/_77)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-97272594e749>\", line 236, in <module>\n    main()\n  File \"<ipython-input-1-97272594e749>\", line 232, in main\n    train_and_sample(i, restore=True)\n  File \"<ipython-input-1-97272594e749>\", line 150, in train_and_sample\n    model.init_graph()\n  File \"<ipython-input-1-97272594e749>\", line 32, in init_graph\n    self.saver = tf.train.Saver(tf.trainable_variables())\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 266, in save_op\n    tensors)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1800, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Failed to rename: ./model.tf.data-00000-of-00001.tempstate17407603199646018557 to: ./model.tf.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, logit_bias/_67, logit_weights/_69, rnn/multi_rnn_cell/cell_0/lstm_cell/bias/_71, rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/_73, rnn/multi_rnn_cell/cell_1/lstm_cell/bias/_75, rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/_77)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Failed to rename: ./model.tf.data-00000-of-00001.tempstate17407603199646018557 to: ./model.tf.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, logit_bias/_67, logit_weights/_69, rnn/multi_rnn_cell/cell_0/lstm_cell/bias/_71, rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/_73, rnn/multi_rnn_cell/cell_1/lstm_cell/bias/_75, rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/_77)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97272594e749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-97272594e749>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n\\nTrain for {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total iters: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mtrain_and_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-97272594e749>\u001b[0m in \u001b[0;36mtrain_and_sample\u001b[0;34m(minibatch_iterations, restore)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reset minibatch feeder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mdata_feed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n sampling after {} iterations'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-97272594e749>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1719\u001b[0m                   save_path))\n\u001b[0;32m-> 1720\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1702\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Failed to rename: ./model.tf.data-00000-of-00001.tempstate17407603199646018557 to: ./model.tf.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, logit_bias/_67, logit_weights/_69, rnn/multi_rnn_cell/cell_0/lstm_cell/bias/_71, rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/_73, rnn/multi_rnn_cell/cell_1/lstm_cell/bias/_75, rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/_77)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-97272594e749>\", line 236, in <module>\n    main()\n  File \"<ipython-input-1-97272594e749>\", line 232, in main\n    train_and_sample(i, restore=True)\n  File \"<ipython-input-1-97272594e749>\", line 150, in train_and_sample\n    model.init_graph()\n  File \"<ipython-input-1-97272594e749>\", line 32, in init_graph\n    self.saver = tf.train.Saver(tf.trainable_variables())\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 266, in save_op\n    tensors)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1800, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Failed to rename: ./model.tf.data-00000-of-00001.tempstate17407603199646018557 to: ./model.tf.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, logit_bias/_67, logit_weights/_69, rnn/multi_rnn_cell/cell_0/lstm_cell/bias/_71, rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/_73, rnn/multi_rnn_cell/cell_1/lstm_cell/bias/_75, rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/_77)]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import time\n",
    "import codecs\n",
    "import locale\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import data_reader\n",
    "\n",
    "class Model(object):\n",
    "    \"\"\"RNN language model.\"\"\"\n",
    "    def __init__(self, batch_size, sequence_length, lstm_sizes, dropout,\n",
    "                 labels, save_path):\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm_sizes = lstm_sizes\n",
    "        self.labels = labels\n",
    "        self.label_map = {val: idx for idx, val in enumerate(labels)}\n",
    "        self.number_of_characters = len(labels)\n",
    "        self.save_path = save_path\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def init_graph(self):\n",
    "        # Variable sequence length\n",
    "        self.inputs = tf.placeholder(\n",
    "            tf.int32, [self.batch_size, self.sequence_length])\n",
    "        self.targets = tf.placeholder(\n",
    "            tf.int32, [self.batch_size, self.sequence_length])\n",
    "        self.init_architecture()\n",
    "        self.saver = tf.train.Saver(tf.trainable_variables())\n",
    "\n",
    "    def init_architecture(self):\n",
    "        # Define a multilayer LSTM cell\n",
    "        self.one_hot_inputs = tf.one_hot(\n",
    "            self.inputs, depth=self.number_of_characters)\n",
    "        cell_list = [tf.nn.rnn_cell.LSTMCell(lstm_size, state_is_tuple=True)\n",
    "                     for lstm_size in self.lstm_sizes]\n",
    "        self.multi_cell_lstm = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            cell_list, state_is_tuple=True)\n",
    "        # Initial state of the LSTM memory.\n",
    "        # Keep state in graph memory to use between batches\n",
    "        self.initial_state = self.multi_cell_lstm.zero_state(\n",
    "            self.batch_size, tf.float32)\n",
    "        # Convert to variables so that the state can be stored between batches\n",
    "        # Note that LSTM states is a tuple of tensors, this structure has to be\n",
    "        # re-created in order to use as LSTM state.\n",
    "        self.state_variables = tf.contrib.framework.nest.pack_sequence_as(\n",
    "            self.initial_state,\n",
    "            [tf.Variable(var, trainable=False)\n",
    "             for var in tf.contrib.framework.nest.flatten(self.initial_state)])\n",
    "        # Define the rnn through time\n",
    "        lstm_output, final_state = tf.nn.dynamic_rnn(\n",
    "            cell=self.multi_cell_lstm, inputs=self.one_hot_inputs,\n",
    "            initial_state=self.state_variables)\n",
    "        # Force the initial state to be set to the new state for the next batch\n",
    "        # before returning the output\n",
    "        store_states = [\n",
    "            state_variable.assign(new_state)\n",
    "            for (state_variable, new_state) in zip(\n",
    "                tf.contrib.framework.nest.flatten(self.state_variables),\n",
    "                tf.contrib.framework.nest.flatten(final_state))]\n",
    "        with tf.control_dependencies(store_states):\n",
    "            lstm_output = tf.identity(lstm_output)\n",
    "        # Reshape so that we can apply the linear transformation to all outputs\n",
    "        output_flat = tf.reshape(lstm_output, (-1, self.lstm_sizes[-1]))\n",
    "        # Define output layer\n",
    "        self.logit_weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                (self.lstm_sizes[-1], self.number_of_characters), stddev=0.01),\n",
    "            name='logit_weights')\n",
    "        self.logit_bias = tf.Variable(\n",
    "            tf.zeros((self.number_of_characters)), name='logit_bias')\n",
    "        # Apply last layer transformation\n",
    "        self.logits_flat = tf.matmul(\n",
    "            output_flat, self.logit_weights) + self.logit_bias\n",
    "        probabilities_flat = tf.nn.softmax(self.logits_flat)\n",
    "        self.probabilities = tf.reshape(\n",
    "            probabilities_flat,\n",
    "            (self.batch_size, -1, self.number_of_characters))\n",
    "\n",
    "    def init_train_op(self, optimizer):\n",
    "        # Flatten the targets to be compatible with the flattened logits\n",
    "        targets_flat = tf.reshape(self.targets, (-1, ))\n",
    "        # Get the loss over all outputs\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits_flat, labels=targets_flat, name='x_entropy')\n",
    "        self.loss = tf.reduce_mean(loss)\n",
    "        trainable_variables = tf.trainable_variables()\n",
    "        gradients = tf.gradients(loss, trainable_variables)\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            gradients, 5)\n",
    "        self.train_op = optimizer.apply_gradients(\n",
    "            zip(gradients, trainable_variables))\n",
    "\n",
    "    def sample(self, session, prime_string, sample_length):\n",
    "        self.reset_state(session)\n",
    "        # Prime state\n",
    "        print('prime_string: ', prime_string)\n",
    "        for character in prime_string:\n",
    "            character_idx = self.label_map[character]\n",
    "            out = session.run(\n",
    "                self.probabilities,\n",
    "                feed_dict={self.inputs: np.asarray([[character_idx]])})\n",
    "            sample_label = np.random.choice(\n",
    "                self.labels, size=(1),  p=out[0, 0])\n",
    "        output_sample = prime_string\n",
    "        print('start sampling')\n",
    "        # Sample for sample_length steps\n",
    "        for _ in range(sample_length):\n",
    "            sample_label = np.random.choice(\n",
    "                self.labels, size=(1),  p=out[0, 0])[0]\n",
    "            output_sample += sample_label\n",
    "            sample_idx = self.label_map[sample_label]\n",
    "            out = session.run(\n",
    "                self.probabilities,\n",
    "                feed_dict={self.inputs: np.asarray([[sample_idx]])})\n",
    "        return output_sample\n",
    "\n",
    "    def reset_state(self, session):\n",
    "        for state in tf.contrib.framework.nest.flatten(self.state_variables):\n",
    "            session.run(state.initializer)\n",
    "\n",
    "    def save(self, sess):\n",
    "        self.saver.save(sess, self.save_path)\n",
    "\n",
    "    def restore(self, sess):\n",
    "        self.saver.restore(sess, self.save_path)\n",
    "\n",
    "\n",
    "def train_and_sample(minibatch_iterations, restore):\n",
    "    tf.reset_default_graph()\n",
    "    batch_size = 64\n",
    "    lstm_sizes = [512, 512]\n",
    "    batch_len = 100\n",
    "    learning_rate = 2e-3\n",
    "\n",
    "    filepath = './wap.txt'\n",
    "\n",
    "    data_feed = data_reader.DataReader(\n",
    "         filepath, batch_len, batch_size)\n",
    "    labels = data_feed.char_list\n",
    "    print('labels: ', labels)\n",
    "\n",
    "    save_path = './model.tf'\n",
    "    model = Model(\n",
    "        batch_size, batch_len, lstm_sizes, 0.8, labels,\n",
    "        save_path)\n",
    "    model.init_graph()\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    model.init_train_op(optimizer)\n",
    "\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        if restore:\n",
    "            print('Restoring model')\n",
    "            model.restore(sess)\n",
    "        model.reset_state(sess)\n",
    "        start_time = time.time()\n",
    "        for i in range(minibatch_iterations):\n",
    "            input_batch, target_batch = next(iter(data_feed))\n",
    "            loss, _ = sess.run(\n",
    "                [model.loss, model.train_op],\n",
    "                feed_dict={\n",
    "                    model.inputs: input_batch, model.targets: target_batch})\n",
    "            if i % 50 == 0 and i != 0:\n",
    "                print('i: ', i)\n",
    "                duration = time.time() - start_time\n",
    "                print('loss: {} ({} sec.)'.format(loss, duration))\n",
    "                start_time = time.time()\n",
    "            if i % 1000 == 0 and i != 0:\n",
    "                model.save(sess)\n",
    "            if i % 100 == 0 and i != 0:\n",
    "                print('Reset initial state')\n",
    "                model.reset_state(sess)\n",
    "            if i % 1000 == 0 and i != 0:\n",
    "                print('Reset minibatch feeder')\n",
    "                data_feed.reset_indices()\n",
    "        model.save(sess)\n",
    "\n",
    "    print('\\n sampling after {} iterations'.format(minibatch_iterations))\n",
    "    tf.reset_default_graph()\n",
    "    model = Model(\n",
    "        1, None, lstm_sizes, 1.0, labels, save_path)\n",
    "    model.init_graph()\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        model.restore(sess)\n",
    "        print('\\nSample 1:')\n",
    "        sample = model.sample(\n",
    "            sess, prime_string=u'\\n\\nThis feeling was ', sample_length=500)\n",
    "        print(u'sample: \\n{}'.format(sample))\n",
    "        print('\\nSample 2:')\n",
    "        sample = model.sample(\n",
    "            sess, prime_string=u'She was born in the year ', sample_length=500)\n",
    "        print(u'sample: \\n{}'.format(sample))\n",
    "        print('\\nSample 3:')\n",
    "        sample = model.sample(\n",
    "            sess, prime_string=u'The meaning of this all is ',\n",
    "            sample_length=500)\n",
    "        print(u'sample: \\n{}'.format(sample))\n",
    "        print('\\nSample 4:')\n",
    "        sample = model.sample(\n",
    "            sess,\n",
    "            prime_string=u'In the midst of a conversation on political matters Anna Pávlovna burst out:,',\n",
    "            sample_length=500)\n",
    "        print(u'sample: \\n{}'.format(sample))\n",
    "        print('\\nSample 5:')\n",
    "        sample = model.sample(\n",
    "            sess, prime_string=u'\\n\\nCHAPTER X\\n\\n',\n",
    "            sample_length=500)\n",
    "        print(u'sample: \\n{}'.format(sample))\n",
    "        print('\\nSample 5:')\n",
    "        sample = model.sample(\n",
    "            sess, prime_string=u'\"If only you knew,\"',\n",
    "            sample_length=500)\n",
    "        print(u'sample: \\n{}'.format(sample))\n",
    "\n",
    "\n",
    "def main():\n",
    "    total_iterations = 500\n",
    "    print('\\n\\n\\nTrain for {}'.format(500))\n",
    "    print('Total iters: {}'.format(total_iterations))\n",
    "    train_and_sample(500, restore=False)\n",
    "    for i in [500, 1000, 3000, 5000, 10000, 30000, 50000, 100000, 300000]:\n",
    "        total_iterations += i\n",
    "        print('\\n\\n\\nTrain for {}'.format(i))\n",
    "        print('Total iters: {}'.format(total_iterations))\n",
    "        train_and_sample(i, restore=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('aaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
